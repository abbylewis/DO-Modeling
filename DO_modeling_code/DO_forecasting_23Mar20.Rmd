---
title: "DO Model Hindcasting"
author: "Abby Lewis"
date: "12/8/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readxl)
library(tidyverse)
library(zoo)
library(deSolve)
library(lubridate)
library(formatR)
library(knitr)
source('EnKF_functions_21Mar20.R')
source('DO_forecasting_functions_24Mar20.R')
source('O2_models_24Mar20.R')
library(magick)
library(animation)
library(Metrics)
```

Created 20 March 20 to convert my model to a forecasting framework
- NOTE: got rid of the flexible hypo volume. I think that's what was destroying 2016
- NOTE: I am saying data collected on the day of the forecast DOES get incorporated into the forecast
- This one script can do normal, temp, o2, and persistence forecasts

To do:
- READ about forecast evaluation
- Look into best practices for archiving forecast runs. Do I need to save all drivers/parameters/etc from each run?
- What am I doing with training vs test data? Is there a way to automatically get the best parameters? 
  - Read about what other people are doing
  - Look at what the parameters are changing to here
- Look at alternative null models. I really think the most informative in my mind would be someone pointing at the graph and saying where they think it will go. Is this a thing?

Should the model only run when you have a new observation?
  - Yes. Drivers aren't changing. There's no point in rerunning the forecast, and this will lead to more noise in the RMSE plot
  - Okay but it does pretty well and managers could potentially use it to predict further into the future even with out a new observation
  - Not a huge priority. Look into best practices for how often the model should be run. Sticking with an even time step for now for simplicity. 

Done:
- Set aside some data as test (2013, 2015, 2019) and some as training (2014, 2016, 2017, 2018): DONE
- Create one forecast half way through 2014: DONE
- Create forecasts for all of 2014: DONE
- Create forecasts for all training years: DONE
- Set this up to archive everything in github: DONE!!
- Calculate RMSE a certain number of days out DONE
- Plot of rmse vs the number of days away, colors for the year DONE
- Archive forecasts DONE
- Create persistence forecast DONE
- Compare RMSE with the persistence forecast to the actual model DONE
- Create forecast with just temp DONE
- Create forecast with just O2 DONE
- Add temp and o2 models to this script DONE
- Just SSS model DONE
- Compare models on a graph DONE


## Parameters
```{r}
## Parameters, CV, number of ensembles
parms <- c(
  R20 = .7, #mg/L/day
  theta = 1.1, 
  ko2 = 1, #mg/L
  sss_scalar = 3
)

# From GLEON workshop 
# I made all of these up more or less randomly. Not sure how I should have come up with them
n_en = 100 # number of ensembles 
# coefficient of variation (CV) as a representation of uncertainty 
param_cv = c(R20 = .1,
             theta = .01,
             ko2 = .1,
             sss_scalar = .2)
driver_cv = c(SSS = .2,
              temp = .2,
              o2_mgL = 0) # Coefficient of variation of driver data 
init_cond_cv = .1
obs_cv = 0.05
```


```{r}
#Create observations dataframe
CTD <- read.csv("../DO_modeling_data/vol_weighted_do_fcr.csv")
CTD = CTD%>%
  filter(hypoVolume>0,
         !is.na(Conc))%>%
  mutate(Date = as.Date(Date))
obs <- CTD %>%
  filter(!is.na(Conc))%>%
  select(Date, Conc)%>%
  rename(datetime = Date)%>%
  group_by(datetime)%>%
  summarize(O2_mgL = mean(Conc))
CTD$hypoVolume<-mean(CTD$hypoVolume, na.rm = TRUE)

mean_hypo_ratio <- mean(CTD$SA_m2/CTD$hypoVolume)
median_hypo_ratio <- median(CTD$SA_m2/CTD$hypoVolume)

#Create driver data frame (called model_inputs)
SSS <- read_excel("../DO_modeling_data/Calc_HOX_flow_DO_20190320.xlsx") 
SSS$time <- as.Date(SSS$time)
  

start = as.Date(c("2013-04-30","2014-06-02","2015-06-08","2016-06-01","2017-06-28","2018-06-04","2019-06-03"))
stop = as.Date(c("2013-08-08","2014-10-15","2015-09-28","2016-10-07","2017-07-12","2018-10-22","2019-10-30"))
avgs <- calc_avg(start,stop,CTD,SSS)
avg_temp<-unlist(avgs[1])
avg_o2<-unlist(avgs[2])

```







Run forecasts!
```{r}
run_space <- 1 #Number of days between runs of the model
n_days <- 14 #Forecast horizon
model_name = "full" #Options for model_name: SSS, temp, o2, full. SSS is no temp no o2, O2 is no temp. Temp is no o2.

#2014
start = as.Date("2014-06-02")
stop = as.Date("2014-10-15")
results_2014 <- runForecasts(start, stop, n_days, run_space, obs, delay = 5, model_name = model_name, gif = F,avg_o2 = avg_o2,avg_temp=avg_temp)
rmse_2014 <- createRmseDF(n_days, results_2014) # Calculate rmse for all days

#2016
start = as.Date("2016-06-01")
stop = as.Date("2016-10-07")
results_2016 <- runForecasts(start, stop, n_days, run_space, obs, delay = 5, model_name = model_name, gif = F,avg_o2 = avg_o2,avg_temp=avg_temp)
rmse_2016 <- createRmseDF(n_days, results_2016)

#2017
start = as.Date("2017-06-28")
stop = as.Date("2017-07-12")
results_2017 <- runForecasts(start, stop, n_days, run_space, obs, delay = 30, model_name = model_name, gif = F,avg_o2 = avg_o2,avg_temp=avg_temp)
rmse_2017 <- createRmseDF(n_days, results_2017)

#2018
start = as.Date("2018-06-04")
stop = as.Date("2018-10-22")
results_2018 <- runForecasts(start, stop, n_days, run_space, obs, delay = 5, model_name = model_name, gif = F,avg_o2 = avg_o2,avg_temp=avg_temp)
rmse_2018 <- createRmseDF(n_days, results_2018)

rmse_total <- rmse_2014%>%
  mutate(Year = 2014)%>%
  full_join(rmse_2016 %>% mutate (Year = 2016))%>%
  full_join(rmse_2017 %>% mutate (Year = 2017))%>%
  full_join(rmse_2018 %>% mutate (Year = 2018))
date <- format(Sys.Date(),"%d%b%y")
write.csv(rmse_total,paste("../DO_modeling_results/rmse_",model_name,"_",date,".csv", sep = ""))

rmse_total%>%
  filter(Year!=2017)%>%
  ggplot(aes(x = n, y = val, col = as.factor(Year)))+
  geom_point()+
  ylab("RMSE")+
  xlab("Days past forecast generation")+
  labs(color = "Year")
```


```{r}
run_space <- 1 #Number of days between runs of the model
n_days <- 14 #Forecast horizon

#2014
start = as.Date("2014-06-02")
stop = as.Date("2014-10-15")
persist_2014 <- persistenceForecast(start, stop, n_days, run_space, obs)
rmse_persist_2014 <- createRmseDF(n_days, persist_2014)

#2016
start = as.Date("2016-06-01")
stop = as.Date("2016-10-07")
persist_2016 <- persistenceForecast(start, stop, n_days, run_space, obs)
rmse_persist_2016 <- createRmseDF(n_days, persist_2016)

#2017
start = as.Date("2017-06-28")
stop = as.Date("2017-07-12")
persist_2017 <- persistenceForecast(start, stop, n_days, run_space, obs)
rmse_persist_2017 <- createRmseDF(n_days, persist_2017)

#2018
start = as.Date("2018-06-04")
stop = as.Date("2018-10-22")
persist_2018 <- persistenceForecast(start, stop, n_days, run_space, obs)
rmse_persist_2018 <- createRmseDF(n_days, persist_2018)

rmse_persist_total <- rmse_persist_2014%>%
  mutate(Year = 2014)%>%
  full_join(rmse_persist_2016 %>% mutate (Year = 2016))%>%
  full_join(rmse_persist_2017 %>% mutate (Year = 2017))%>%
  full_join(rmse_persist_2018 %>% mutate (Year = 2018))
date <- format(Sys.Date(),"%d%b%y")
write.csv(rmse_persist_total,paste("../DO_modeling_results/rmse_persist_",date,".csv", sep = ""))

rmse_persist_total%>%
  filter(Year!=2017)%>%
  ggplot(aes(x = n, y = val, col = as.factor(Year)))+
  geom_point()+
  ylab("RMSE")+
  xlab("Days past forecast generation")+
  labs(color = "Year")
```

```{r}
rmse_comb <- rmse_persist_total%>%
  mutate(Model = "persistance")%>%
  full_join(rmse_total %>% mutate(Model = "forecast"))

rmse_comb %>%
  filter(Year!=2017)%>%
  ggplot(aes(x = n, y = val, color = Model, shape = as.factor(Year)))+
  geom_point()+
  ylab("RMSE")+
  xlab("Days past forecast generation")+
  labs(shape = "Year")
```

```{r}
temp <- read.csv("../DO_modeling_results/rmse_temp_24Mar20.csv")
o2 <- read.csv("../DO_modeling_results/rmse_o2_24Mar20.csv")
full <- read.csv("../DO_modeling_results/rmse_full_24Mar20.csv")
sss <- read.csv("../DO_modeling_results/rmse_sss_24Mar20.csv")
persist <- read.csv("../DO_modeling_results/rmse_persist_24Mar20.csv")

rmse_all <- persist%>%
  mutate(Model = "persistance")%>%
  full_join(full %>% mutate(Model = "full"))%>%
  full_join(o2 %>% mutate(Model = "o2"))%>%
  full_join(temp %>% mutate(Model = "temp"))%>%
  full_join(sss %>% mutate(Model = "sss"))

date <- format(Sys.Date(),"%d%b%y")
jpeg(paste("../DO_modeling_figures/",date,"/RMSE_all.jpeg",sep = ""),width = 5, height = 2, unit = "in", res = 300)
rmse_all %>%
  filter(Year!=2017)%>%
  ggplot(aes(x = n, y = val, color = Model))+
  geom_line()+
  ylab("RMSE")+
  xlab("Days past forecast generation")+
  facet_wrap("Year")
dev.off()
```


SKIP: this would plot parameter values over 
#```{r}
plot(inputs_2016$Date,inputs_2016$Chla, )


start = as.Date("2016-06-01")
stop = as.Date("2016-10-07")
inputs_2016 <- inputs_year(start,stop)
today <- start
dir.create("../DO_modeling_figures/3Mar20/2016_param")
setwd("../DO_modeling_figures/3Mar20/2016_param")
png(file="example%02d.png", width=480, height=480)
while(today < stop){
  est2016 <- run_do_hindcast(inputs_2016, obs, today)
  plot_param(est2016, 1)
  plot_param(est2016, 2)
  plot_param(est2016, 3)
  plot_param(est2016, 4)
  plot_param(est2016, 5)
  today <- today+2
}
#```

Saving the best dates for the start and end of each season
```{r}
start = as.Date("2013-04-30")
stop = as.Date("2013-08-08")
start = as.Date("2014-06-02")
stop = as.Date("2014-10-15")
start = as.Date("2015-06-08")
stop = as.Date("2015-09-28")
start = as.Date("2016-06-01")
stop = as.Date("2016-10-07")
start = as.Date("2017-06-28")
stop = as.Date("2017-07-12")
start = as.Date("2018-06-04")
stop = as.Date("2018-10-22")
start = as.Date("2019-06-03")
stop = as.Date("2019-10-30")
```


Just for troubleshooting:
```{r}
n_en = n_en
start = start
stop = stop
time_step = "days"
obs_file = obs
driver_file = model_inputs
n_states_est = 1
n_params_est = 4
n_params_obs = 0
n_drivers = 6
parm_init = parms
obs_cv = obs_cv
param_cv = param_cv
driver_cv = driver_cv
init_cond_cv = init_cond_cv
```

Notes for next steps: 
Informed priors for parameters (there are points where r20 = -20)
Make it so that the kalman filter only runs when there's an observation -- the idea of comparing it to 0 seems v sketch???
Quantify uncertainty at each time step
Run for other years